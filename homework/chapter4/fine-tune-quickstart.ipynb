{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90c6730f-5d76-450b-9788-ec883d024f57",
   "metadata": {},
   "source": [
    "# Hugging Face Transformers 微调训练入门\n",
    "\n",
    "本示例将介绍基于 Transformers 实现模型微调训练的主要流程，包括：\n",
    "- 数据集下载\n",
    "- 数据预处理\n",
    "- 训练超参数配置\n",
    "- 训练评估指标设置\n",
    "- 训练器基本介绍\n",
    "- 实战训练\n",
    "- 模型保存"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0b1e12-1921-4438-8d5d-9760a629dcfe",
   "metadata": {},
   "source": [
    "## YelpReviewFull 数据集\n",
    "\n",
    "**Hugging Face 数据集：[ YelpReviewFull ](https://huggingface.co/datasets/yelp_review_full)**\n",
    "\n",
    "### 数据集摘要\n",
    "\n",
    "Yelp评论数据集包括来自Yelp的评论。它是从Yelp Dataset Challenge 2015数据中提取的。\n",
    "\n",
    "### 支持的任务和排行榜\n",
    "文本分类、情感分类：该数据集主要用于文本分类：给定文本，预测情感。\n",
    "\n",
    "### 语言\n",
    "这些评论主要以英语编写。\n",
    "\n",
    "### 数据集结构\n",
    "\n",
    "#### 数据实例\n",
    "一个典型的数据点包括文本和相应的标签。\n",
    "\n",
    "来自YelpReviewFull测试集的示例如下：\n",
    "\n",
    "```json\n",
    "{\n",
    "    'label': 0,\n",
    "    'text': 'I got \\'new\\' tires from them and within two weeks got a flat. I took my car to a local mechanic to see if i could get the hole patched, but they said the reason I had a flat was because the previous patch had blown - WAIT, WHAT? I just got the tire and never needed to have it patched? This was supposed to be a new tire. \\\\nI took the tire over to Flynn\\'s and they told me that someone punctured my tire, then tried to patch it. So there are resentful tire slashers? I find that very unlikely. After arguing with the guy and telling him that his logic was far fetched he said he\\'d give me a new tire \\\\\"this time\\\\\". \\\\nI will never go back to Flynn\\'s b/c of the way this guy treated me and the simple fact that they gave me a used tire!'\n",
    "}\n",
    "```\n",
    "\n",
    "#### 数据字段\n",
    "\n",
    "- 'text': 评论文本使用双引号（\"）转义，任何内部双引号都通过2个双引号（\"\"）转义。换行符使用反斜杠后跟一个 \"n\" 字符转义，即 \"\\n\"。\n",
    "- 'label': 对应于评论的分数（介于1和5之间）。\n",
    "\n",
    "#### 数据拆分\n",
    "\n",
    "Yelp评论完整星级数据集是通过随机选取每个1到5星评论的130,000个训练样本和10,000个测试样本构建的。总共有650,000个训练样本和50,000个测试样本。\n",
    "\n",
    "## 下载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbf72d6c-7ea5-4ee1-969a-c5060b9cb2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/peft/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"yelp_review_full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec6fc806-1395-42dd-8121-a6e98a95cf01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 650000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c94ad529-1604-48bd-8c8d-aa2f3bca6200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 2,\n",
       " 'text': \"As far as Starbucks go, this is a pretty nice one.  The baristas are friendly and while I was here, a lot of regulars must have come in, because they bantered away with almost everyone.  The bathroom was clean and well maintained and the trash wasn't overflowing in the canisters around the store.  The pastries looked fresh, but I didn't partake.  The noise level was also at a nice working level - not too loud, music just barely audible.\\\\n\\\\nI do wish there was more seating.  It is nice that this location has a counter at the end of the bar for sole workers, but it doesn't replace more tables.  I'm sure this isn't as much of a problem in the summer when there's the space outside.\\\\n\\\\nThere was a treat receipt promo going on, but the barista didn't tell me about it, which I found odd.  Usually when they have promos like that going on, they ask everyone if they want their receipt to come back later in the day to claim whatever the offer is.  Today it was one of their new pastries for $1, I know in the summer they do $2 grande iced drinks with that morning's receipt.\\\\n\\\\nOverall, nice working or socializing environment.  Very friendly and inviting.  It's what I've come to expect from Starbucks, so points for consistency.\"}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][111]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dc45997-e391-456f-b0b9-d3193b0f6a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import datasets\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e2ecebb-d5d1-456d-967c-842a79fdd622",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_random_elements(dataset, num_examples=10):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "    \n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, datasets.ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1af560b6-7d21-499e-9b82-114be371a98a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2 star</td>\n",
       "      <td>Stopped in here around 12:30 right before start of big Panther's playoff game.  It was one of the closest bars to our hotel other then Ruby Tuesday's that we could walk to.   It was still 2.5 miles but a nice day.    Sat at the bar and had drinks. Drinks are good and reasonably priced.  Shared a bowl of the potato soup which was also good.   Shared appetizer sampler.  I NEVER get appetizer samplers that consist of chicken tenders and potato skins.   i think both are stupid.   However after ready all the great reviews about Ocharley's chicken fingers I thought we would give it a shot.   they were overcooked and tastae like a chicken finger off any kids meal at any chain restaurant.   Potato skins are potato skins.    These both get 2.  the cheese things however were great!   \\nMade a stop the following week  for hh.   Another margarita not as good as the one at the bar first time.  Was lured in by hh priced nachos.   Cheese whiz?   Not!  \\nThe only good thing was my first margaritaand the cheese triangles.   And the soup.\\nand serivce was horrible the 2nd time!!  Took forever to get check!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3 stars</td>\n",
       "      <td>I bought a groupon and used it right away. Scheduling an appointment was very easy. When I went, I guess they had just relocated their office? So it was very hard for me to find as there was no signs up or anything. The front desk people were very nice &amp; the owner was a sweetheart as well. The lady who did my lashes was nice as well. She kept the whole appointment conversational which I enjoyed because it was a fairly long appointment and it kept me entertained. The only reason why I gave this a three star is because my lashes did not last two days :/ I followed all the instructions given to me. Did not wear make up for 48 hours, did not use anything I wasn't suppose to. After the recommended time to wait befor getting them wet...I washed my face and one by one my lashes were falling off. It didn't even last a week for my family party I had coming up. I was extremely bummed as I paid $60 or so on this groupon. Not sure if it was the application or products used to apply them...but I can assume you 100% I followed the aftercare instructions as I was really trying to get then to last until the family gathering...but it didn't :(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1 star</td>\n",
       "      <td>They got my order wrong and the food tasted old. My malt tasted really bad like they made if with expired icecream. I got only have my order. I'm not eating here again or at any Carl's jr was the worse service I have received.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2 star</td>\n",
       "      <td>The food tastes good but the portions are small and the plates are expensive.\\n\\nThe atmosphere is \\\"cute\\\". If you have kids it is hard to guess if they would like it or hate it. (I've seen some kids get excited and others become frightened.)\\n\\nI've eaten at the Phoenix and Las Vegas locations.... honestly, I could take it or leave it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1 star</td>\n",
       "      <td>I will not be coming back here! A whole lot of energy spent on making the food look good instead of tasting good! Nasty, watered down sushi!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2 star</td>\n",
       "      <td>Its been a long time. And better left as a memory. Had the Double-Double Animal Style. Just another really average fast food burger. Maybe I know my food too well. One thing I know for sure. No more In-N-Out for me. This is big calories and fat grams. If I treat myself, it won't be for this stuff again. Period.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1 star</td>\n",
       "      <td>Ordered from here on 11/19/14 and it took over 2 hours to arrive and the food was cold and basically inedible. When I called to complain, they refused to issue a refund. The food is not good enough to put up with the headache and terrible customer service. I'd suggest trying somewhere else.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1 star</td>\n",
       "      <td>Have been there a handful of times. Service and food are less than average. Just sat at the bar for over 5 minutes and not only did we not receive service, but the bartender literally looked past/through us to the people sitting in either side of us. She didn't even say she'd be right with us or acknowledge us in any way. We walked out out and went straight to Blue 32, which, not surprisingly, is packed for happy hour... they clearly don't have any real competition. Harvey American needs to step up their service and menu.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1 star</td>\n",
       "      <td>Worst place in concord...went there tonight after a wedding we went to waited 35 min to get a burger. When it came it was warm and not hot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1 star</td>\n",
       "      <td>Okay I'm standing in check out line because I have an iPhone power cable that I need to purchase because iPhone power cables have to be made by Apple. I will never purchase an iPhone again. But wait there's more the REAL apple iPhone power cables are not in the mobile phone accessory section they're actually in a different part of the store not by the Apple products. Back to the checkout line so I'm standing in the checkout line watching all the 4 employees standing at the front door talking and there's only one girl at the register.  Then another customer walks up to the employees and shows them a phone cover and the employee walks over to the closed register and opens it up and check him out. While the rest of us are standing in line watching this transaction.  I'm thinking this is fantastic that's what I should've done. But wait there's more I get to the register with my $20 APPLE cord for my iPhone and the girl asked to see my ID with my credit card. I'm thinking wow this is a huge purchase she better check my ID. I can get better service at the $.99 store. NEVER GOING TO BEST BUY AGAIN!  I approve this message JK KUHL....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(dataset[\"train\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9df7cd0-23cd-458f-b2b5-f025c3b9fe62",
   "metadata": {},
   "source": [
    "## 预处理数据\n",
    "\n",
    "下载数据集到本地后，使用 Tokenizer 来处理文本，对于长度不等的输入数据，可以使用填充（padding）和截断（truncation）策略来处理。\n",
    "\n",
    "Datasets 的 `map` 方法，支持一次性在整个数据集上应用预处理函数。\n",
    "\n",
    "下面使用填充到最大长度的策略，处理整个数据集："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bf2b342-e1dd-4ab6-ad57-28eb2513ae38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/peft/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Map: 100%|██████████| 50000/50000 [00:12<00:00, 3882.35 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47a415a8-cd15-4a8c-851b-9b4740ef8271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>token_type_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 star</td>\n",
       "      <td>Been waiting 2 hours to be seen by a vet. Only one person in front of us when we got here. My dog has been throwing up blood in the waiting room and despite our complaining, still no vet. If there are other 24 hour animal hospitals use them.</td>\n",
       "      <td>[101, 18511, 2613, 123, 2005, 1106, 1129, 1562, 1118, 170, 1396, 1204, 119, 2809, 1141, 1825, 1107, 1524, 1104, 1366, 1165, 1195, 1400, 1303, 119, 1422, 3676, 1144, 1151, 6558, 1146, 1892, 1107, 1103, 2613, 1395, 1105, 2693, 1412, 19533, 117, 1253, 1185, 1396, 1204, 119, 1409, 1175, 1132, 1168, 1572, 2396, 3724, 8894, 1329, 1172, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(tokenized_datasets[\"train\"], num_examples=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c33d153-f729-4f04-972c-a764c1cbbb8b",
   "metadata": {},
   "source": [
    "### 数据抽样\n",
    "\n",
    "使用 1000 个数据样本，在 BERT 上演示小规模训练（基于 Pytorch Trainer）\n",
    "\n",
    "`shuffle()`函数会随机重新排列列的值。如果您希望对用于洗牌数据集的算法有更多控制，可以在此函数中指定generator参数来使用不同的numpy.random.Generator。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a17317d8-3c6a-467f-843d-87491f600db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000))\n",
    "small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b65d63-2d3a-4a56-bc31-6e88a29e9dec",
   "metadata": {},
   "source": [
    "## 微调训练配置\n",
    "\n",
    "### 加载 BERT 模型\n",
    "\n",
    "警告通知我们正在丢弃一些权重（`vocab_transform` 和 `vocab_layer_norm` 层），并随机初始化其他一些权重（`pre_classifier` 和 `classifier` 层）。在微调模型情况下是绝对正常的，因为我们正在删除用于预训练模型的掩码语言建模任务的头部，并用一个新的头部替换它，对于这个新头部，我们没有预训练的权重，所以库会警告我们在用它进行推理之前应该对这个模型进行微调，而这正是我们要做的事情。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d2af4df-abd4-4a4b-94b6-b0e7375304ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44014df-b52c-4c72-9e9f-54424725a473",
   "metadata": {},
   "source": [
    "### 训练超参数（TrainingArguments）\n",
    "\n",
    "完整配置参数与默认值：https://huggingface.co/docs/transformers/v4.36.1/en/main_classes/trainer#transformers.TrainingArguments\n",
    "\n",
    "源代码定义：https://github.com/huggingface/transformers/blob/v4.36.1/src/transformers/training_args.py#L161\n",
    "\n",
    "**最重要配置：模型权重保存路径(output_dir)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98c01d5c-de72-4ff0-b11d-e07ac5346888",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "model_dir = \"models/bert-base-cased-finetune-yelp\"\n",
    "\n",
    "# logging_steps 默认值为500，根据我们的训练数据和步长，将其设置为100\n",
    "training_args = TrainingArguments(output_dir=model_dir,\n",
    "                                  per_device_train_batch_size=16,\n",
    "                                  num_train_epochs=5,\n",
    "                                  logging_steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ce03480-3aaa-48ea-a0c6-a177b8d8e34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_persistent_workers=False,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "dispatch_batches=None,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=False,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "gradient_checkpointing_kwargs=None,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_always_push=False,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "include_num_input_tokens_seen=False,\n",
      "include_tokens_per_second=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=5e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=models/bert-base-cased-finetune-yelp/runs/Aug30_01-31-34_autodl-container-e7e742ba1d-8ef8a8d1,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=100,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_kwargs={},\n",
      "lr_scheduler_type=linear,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "neftune_noise_alpha=None,\n",
      "no_cuda=False,\n",
      "num_train_epochs=5,\n",
      "optim=adamw_torch,\n",
      "optim_args=None,\n",
      "output_dir=models/bert-base-cased-finetune-yelp,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=16,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=models/bert-base-cased-finetune-yelp,\n",
      "save_on_each_node=False,\n",
      "save_only_model=False,\n",
      "save_safetensors=True,\n",
      "save_steps=500,\n",
      "save_strategy=steps,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "skip_memory_metrics=True,\n",
      "split_batches=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_cpu=False,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 完整的超参数配置\n",
    "print(training_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebd3365-d359-4ab4-a300-4717590cc240",
   "metadata": {},
   "source": [
    "### 训练过程中的指标评估（Evaluate)\n",
    "\n",
    "**[Hugging Face Evaluate 库](https://huggingface.co/docs/evaluate/index)** 支持使用一行代码，获得数十种不同领域（自然语言处理、计算机视觉、强化学习等）的评估方法。 当前支持 **完整评估指标：https://huggingface.co/evaluate-metric**\n",
    "\n",
    "训练器（Trainer）在训练过程中不会自动评估模型性能。因此，我们需要向训练器传递一个函数来计算和报告指标。 \n",
    "\n",
    "Evaluate库提供了一个简单的准确率函数，您可以使用`evaluate.load`函数加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a8ef138-5bf2-41e5-8c68-df8e11f4e98f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 4.20kB [00:00, 3.63MB/s]                   \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d406c0-56d0-4a54-9c6c-e126ab7f5254",
   "metadata": {},
   "source": [
    "\n",
    "接着，调用 `compute` 函数来计算预测的准确率。\n",
    "\n",
    "在将预测传递给 compute 函数之前，我们需要将 logits 转换为预测值（**所有Transformers 模型都返回 logits**）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f46d2e59-1ebf-43d2-bc86-6b57a4d24d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2feba67-9ca9-4793-9a15-3eaa426df2a1",
   "metadata": {},
   "source": [
    "#### 训练过程指标监控\n",
    "\n",
    "通常，为了监控训练过程中的评估指标变化，我们可以在`TrainingArguments`指定`evaluation_strategy`参数，以便在 epoch 结束时报告评估指标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afaaee18-4986-4e39-8ad9-b8d413ab4cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(output_dir=model_dir,\n",
    "                                  evaluation_strategy=\"epoch\", \n",
    "                                  per_device_train_batch_size=16,\n",
    "                                  num_train_epochs=3,\n",
    "                                  logging_steps=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47d6981-e444-4c0f-a7cb-dd7f2ba8df12",
   "metadata": {},
   "source": [
    "## 开始训练\n",
    "\n",
    "### 实例化训练器（Trainer）\n",
    "\n",
    "`kernel version` 版本问题：暂不影响本示例代码运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca1d12ac-89dc-4c30-8282-f859724c0062",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=small_train_dataset,\n",
    "    eval_dataset=small_eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a833e0db-1168-4a3c-8b75-bfdcef8c5157",
   "metadata": {},
   "source": [
    "## 使用 nvidia-smi 查看 GPU 使用\n",
    "\n",
    "为了实时查看GPU使用情况，可以使用 `watch` 指令实现轮询：`watch -n 1 nvidia-smi`:\n",
    "\n",
    "```shell\n",
    "Every 1.0s: nvidia-smi                                                   Wed Dec 20 14:37:41 2023\n",
    "\n",
    "Wed Dec 20 14:37:41 2023\n",
    "+---------------------------------------------------------------------------------------+\n",
    "| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n",
    "|-----------------------------------------+----------------------+----------------------+\n",
    "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
    "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
    "|                                         |                      |               MIG M. |\n",
    "|=========================================+======================+======================|\n",
    "|   0  Tesla T4                       Off | 00000000:00:0D.0 Off |                    0 |\n",
    "| N/A   64C    P0              69W /  70W |   6665MiB / 15360MiB |     98%      Default |\n",
    "|                                         |                      |                  N/A |\n",
    "+-----------------------------------------+----------------------+----------------------+\n",
    "\n",
    "+---------------------------------------------------------------------------------------+\n",
    "| Processes:                                                                            |\n",
    "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
    "|        ID   ID                                                             Usage      |\n",
    "|=======================================================================================|\n",
    "|    0   N/A  N/A     18395      C   /root/miniconda3/bin/python                6660MiB |\n",
    "+---------------------------------------------------------------------------------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "accfe921-471d-481a-96da-c491cdebad0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='189' max='189' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [189/189 00:53, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.312400</td>\n",
       "      <td>1.158425</td>\n",
       "      <td>0.523000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.987600</td>\n",
       "      <td>0.986177</td>\n",
       "      <td>0.579000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.689800</td>\n",
       "      <td>0.986947</td>\n",
       "      <td>0.602000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=189, training_loss=1.0441632952008928, metrics={'train_runtime': 54.2646, 'train_samples_per_second': 55.285, 'train_steps_per_second': 3.483, 'total_flos': 789354427392000.0, 'train_loss': 1.0441632952008928, 'epoch': 3.0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d581099-37a4-4470-b051-1ada38554089",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_test_dataset = tokenized_datasets[\"test\"].shuffle(seed=64).select(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ffb47eab-1370-491e-8a84-6d5347a350b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.0492419004440308,\n",
       " 'eval_accuracy': 0.52,\n",
       " 'eval_runtime': 0.6,\n",
       " 'eval_samples_per_second': 166.675,\n",
       " 'eval_steps_per_second': 21.668,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(small_test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a55686-7c43-4ab8-a5cd-0e77f14c7c52",
   "metadata": {},
   "source": [
    "### 保存模型和训练状态\n",
    "\n",
    "- 使用 `trainer.save_model` 方法保存模型，后续可以通过 from_pretrained() 方法重新加载\n",
    "- 使用 `trainer.save_state` 方法保存训练状态"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad0cbc14-9ef7-450f-a1a3-4f92b6486f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6e30510-0536-49d4-8e1b-43fc25272bde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "badf5868-2847-439d-a73e-42d1cca67b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9441ad-f65a-42b7-9016-4809c78285e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd92e35d-fed7-4ff2-aa84-27b5e29b917a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.model.save_pretrained(\"./\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61828934-01da-4fc3-9e75-8d754c25dfbc",
   "metadata": {},
   "source": [
    "## Homework: 使用完整的 YelpReviewFull 数据集训练，看 Acc 最高能到多少"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffdfb3b0-ac89-4aae-a4ae-9c8d91aac724",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/peft/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"yelp_review_full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0945b30-a9cc-4b8f-9346-2d68843f7cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/peft/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a020db6-0975-4206-bacb-182171c48963",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "model_dir = \"models/full-bert-base-cased-finetune-yelp\"\n",
    "\n",
    "# logging_steps 默认值为500\n",
    "training_args = TrainingArguments(output_dir=model_dir,\n",
    "                                  evaluation_strategy=\"epoch\", \n",
    "                                  per_device_train_batch_size=16,\n",
    "                                  num_train_epochs=3,\n",
    "                                  logging_steps=2000,\n",
    "                                  log_level='info',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56b47558-739b-489b-8caf-86d9e4399e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/peft/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "972feda9-70b8-49af-8aae-39250d58aea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c17d408d-3fe9-4183-b2a1-794043ee7cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f64faf6-9adc-406a-8e7a-7c559e13f7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model from models/full-bert-base-cased-finetune-yelp/checkpoint-31500.\n",
      "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running training *****\n",
      "  Num examples = 650,000\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 64\n",
      "  Training with DataParallel so batch size has been adjusted to: 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 121,875\n",
      "  Number of trainable parameters = 108,314,117\n",
      "  Continuing training from checkpoint, will skip to saved global_step\n",
      "  Continuing training from epoch 0\n",
      "  Continuing training from global step 31500\n",
      "  Will skip the first 0 epochs then the first 31500 batches in the first epoch.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='121875' max='121875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [121875/121875 5:31:02, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.766100</td>\n",
       "      <td>0.753692</td>\n",
       "      <td>0.671440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.691800</td>\n",
       "      <td>0.730348</td>\n",
       "      <td>0.686040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.589300</td>\n",
       "      <td>0.732268</td>\n",
       "      <td>0.691280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-32000\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-32000/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-32000/model.safetensors\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-32500\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-32500/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-32500/model.safetensors\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-33000\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-33000/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-33000/model.safetensors\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-33500\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-33500/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-33500/model.safetensors\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-34000\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-34000/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-34000/model.safetensors\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-34500\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-34500/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-34500/model.safetensors\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-35000\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-35000/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-35000/model.safetensors\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-35500\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-35500/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-35500/model.safetensors\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-36000\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-36000/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-36000/model.safetensors\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-37000\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-37000/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-37000/model.safetensors\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-37500\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-37500/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-37500/model.safetensors\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-38000\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-38000/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-38000/model.safetensors\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-38500\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-38500/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-38500/model.safetensors\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-39000\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-39000/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-39000/model.safetensors\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-39500\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-39500/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-39500/model.safetensors\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-77500\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-77500/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-77500/model.safetensors\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-78000\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-78000/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-78000/model.safetensors\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-78500\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-78500/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-78500/model.safetensors\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-79000\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-79000/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-79000/model.safetensors\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-79500\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-79500/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-79500/model.safetensors\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-80000\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-80000/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-80000/model.safetensors\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-93500\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-93500/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-93500/model.safetensors\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-94000\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-94000/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-94000/model.safetensors\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-94500\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-94500/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-94500/model.safetensors\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-95000\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-95000/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-95000/model.safetensors\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-95500\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-95500/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-95500/model.safetensors\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-96000\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-96000/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-96000/model.safetensors\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-96500\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-96500/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-96500/model.safetensors\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-97000\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-97000/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-97000/model.safetensors\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-97500\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-97500/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-97500/model.safetensors\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-98000\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-98000/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-98000/model.safetensors\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-98500\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-98500/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-98500/model.safetensors\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-99000\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-99000/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-99000/model.safetensors\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-99500\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-99500/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-99500/model.safetensors\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-100000\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-100000/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-100000/model.safetensors\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-100500\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-100500/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-100500/model.safetensors\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-101000\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-101000/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-101000/model.safetensors\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-101500\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-101500/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-101500/model.safetensors\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-102500\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-102500/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-102500/model.safetensors\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-103000\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-103000/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-103000/model.safetensors\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-103500\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-103500/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-103500/model.safetensors\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-104000\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-104000/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-104000/model.safetensors\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-104500\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-104500/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-104500/model.safetensors\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-105000\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-105000/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-105000/model.safetensors\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-105500\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-105500/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-105500/model.safetensors\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-106000\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-106000/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-106000/model.safetensors\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-106500\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-106500/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-106500/model.safetensors\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-107000\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-107000/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-107000/model.safetensors\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-107500\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-107500/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-107500/model.safetensors\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-108000\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-108000/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-108000/model.safetensors\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-108500\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-108500/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-108500/model.safetensors\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-109000\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-109000/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-109000/model.safetensors\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-109500\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-109500/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-109500/model.safetensors\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-110000\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-110000/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-110000/model.safetensors\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-110500\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-110500/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-110500/model.safetensors\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-111000\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-111000/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-111000/model.safetensors\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-111500\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-111500/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-111500/model.safetensors\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-112000\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-112000/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-112000/model.safetensors\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-112500\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-112500/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-112500/model.safetensors\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-113000\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-113000/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-113000/model.safetensors\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-113500\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-113500/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-113500/model.safetensors\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-114000\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-114000/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-114000/model.safetensors\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-114500\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-114500/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-114500/model.safetensors\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-115000\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-115000/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-115000/model.safetensors\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-115500\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-115500/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-115500/model.safetensors\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-116000\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-116000/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-116000/model.safetensors\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-116500\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-116500/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-116500/model.safetensors\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-117000\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-117000/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-117000/model.safetensors\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-117500\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-117500/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-117500/model.safetensors\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-118000\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-118000/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-118000/model.safetensors\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-118500\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-118500/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-118500/model.safetensors\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-119000\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-119000/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-119000/model.safetensors\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-119500\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-119500/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-119500/model.safetensors\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-120000\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-120000/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-120000/model.safetensors\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-120500\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-120500/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-120500/model.safetensors\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-121000\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-121000/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-121000/model.safetensors\n",
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-121500\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-121500/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/tmp-checkpoint-121500/model.safetensors\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=121875, training_loss=0.49798750901442307, metrics={'train_runtime': 19863.0036, 'train_samples_per_second': 98.172, 'train_steps_per_second': 6.136, 'total_flos': 5.130803778048e+17, 'train_loss': 0.49798750901442307, 'epoch': 3.0})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trainer.train()\n",
    "trainer.train(resume_from_checkpoint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34e98f6c-502f-48e1-8d13-fd5888ac8b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to models/full-bert-base-cased-finetune-yelp\n",
      "Configuration saved in models/full-bert-base-cased-finetune-yelp/config.json\n",
      "Model weights saved in models/full-bert-base-cased-finetune-yelp/model.safetensors\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(model_dir)\n",
    "trainer.save_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03d41e2-fe94-47fa-84a2-e9da3f358999",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
